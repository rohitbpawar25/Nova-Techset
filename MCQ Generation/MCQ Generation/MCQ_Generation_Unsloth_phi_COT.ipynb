{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_O40jTU2b12",
        "outputId": "32e7c8eb-7d35-4f44-c862-a6c7843f543e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m794.9/794.9 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m290.7/290.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m141.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "rasterio 1.4.4 requires click!=8.2.*,>=4.0, but you have click 8.2.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install unsloth accelerate bitsandbytes transformers datasets\n",
        "!pip -q install trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "50HIV0ob2tkE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create a folder in the current working directory\n",
        "os.mkdir('cot_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710,
          "referenced_widgets": [
            "b15eefacf37344919620503d6aadff53",
            "68134aea4859481cbf54529bff179c3c",
            "42ee35a06dd24877863ef64c5d35a110",
            "5c5afb1b5d884befbe7787cd3f19d3bc",
            "f98578029de8456ca7107ada3cb4ddee",
            "ccf976bc18e1422d8af57957ef2e7572",
            "e5640336d2ee4aa0ac9f41a5466b193f",
            "66f7285e691d4468b7afdfdf1ccb5ef7",
            "05ce92be53854e3eac5050c08e639622",
            "6f5cfa7f286e4af1905d39af56fa7ec9",
            "b11ee4fa36084283af79f3d3f08e9c29",
            "6e4e1e71679b41bba4ffcd99f6f15063",
            "a7c4c4cdd6634cfdbdfd77a2dbfe2960",
            "39e3dbed96ff42c3a355dc84fb4abffa",
            "c4b4200125784d979ddf247ea910b7d0",
            "71db81ab8c7c42aab9eea2b4136a5125",
            "6c0b2b0fcf824382b0356d3785ae1a82",
            "28942080885443a48e7182812a7ef4e7",
            "3d415db0ea3840c89569405d0d91f6a1",
            "8579040b5b424f50b172cac93c0337b2",
            "8a5aaf2d22734347b8169824e772f034",
            "8f7d1cb78dbe4c99bee09167024b326b",
            "808b4d509cc44a4495b5d7d43785d38f",
            "0d92c11992df4036b1cf79e9b8f271ef",
            "819e41877052441ebfae19b50365b02b",
            "f6816d58d4c84130a25529a0ec10a667",
            "5e1bd63d76a64b7094cebb715d05f93f",
            "50394728447742f8ab2b9ea0c789b0fe",
            "94471f42c68e46a88584fcf9b27e136d",
            "68ed57d70f85496a8dc9e85928bc5599",
            "467cb87239464e7c86999290f82e87a8",
            "41ad9837117e49b8b9b5dc4c1bc313fa",
            "dae066380e9a48f69bdbd7473c860569",
            "1b8605ad0efc446b933095c51c2edb86",
            "c8aa4c8cddba42a99ca326db2e0a54ab",
            "c6052d0e1d0b4db69f5794bfb1e8a41c",
            "a642c8b50c244e719df3f924c5b9453b",
            "db212ecce5c846fbb02f88af9ae5fef1",
            "286f53939041443480b54ed3ce63da4a",
            "70d77c58f0b64463b772d8c9b7c546b2",
            "b5db3571622645fab9e5c892b9c761c9",
            "e479f53267a54a2da3d2a7cdcf00fe56",
            "b0c2288a067b46049523b96215bd0825",
            "25bb4ec9ea69435db6aba5608f364380",
            "8bfb0fdd07d048c595500f99a9f011e5",
            "2e6b77fef3bf46abb1d203e5b38cb729",
            "e4a4f10c04514b448cdfa1e174ccd59c",
            "723095be893c471b9c46d21418ba046f",
            "d3d748559ed54931a0717002d2a7cc30",
            "758343ec90b64d8a9cbc587df2323333",
            "0b1de8be994b4f89a8fccfea2647b119",
            "6853f2a36b364209ab590c793d870bc3",
            "3f5ae2202076400fb54344e18779b3d9",
            "86653629c2fd417c80c760fae1d84c6f",
            "74f02c5c57164323a2921836d26f2acd",
            "0a8ae4fc29e14f44a63a8b4a6ae3e099",
            "7744fd498ccc4d7f94c8b5ff737750b2",
            "cbb10b1f649444e1b8d3e99bea419b5f",
            "91fef0873dd84b2eb8eb4e2019a41a44",
            "af452aa0f6d44f959b8c5df73bc15a19",
            "295013c87f904931b90f8b4a40c60743",
            "b71b5d1e9d364337a992fa67b3458869",
            "30e3e207f63b49c580e6acfd2fe5fd11",
            "ba9332e81b5949049fb84fb5a44e5fd1",
            "52e81bc3083643eb87994a1037b1fbcc",
            "deec8f2626a64a9bbf854f20e1300f61",
            "728b24fe331a44ce8308ddeac8052e0c",
            "a09599d90bd24e1dbbd10056f1c892f6",
            "8378dfaebb4f483bb679f70f0a4a5fb0",
            "09f511ebba334065812f785d1c4bcad3",
            "78e0ea6bc2ae4947bb0c283b94943299",
            "deaa25c5dc5a419d837c2cad564660f0",
            "0a7d5704d90e4fc8845ef91d7664964c",
            "750e206db467469ca3ac21ae921f54f3",
            "906cad77481843c2bdca9538e5e95db2",
            "5c068acf5c8441da8ad8c62028f0c5a2",
            "70a3b8ead5b54e7c85c17a70e5f13b15",
            "3f6775dcd2d34eebbf3e8d7cd7f3f491",
            "9a04ff0ae6ba4257b1975038a051fd16",
            "31a314f814934e5698428c9b61662d87",
            "c65af38f5d284e0aa51a2cf78c031858",
            "5aa7ec39b00f4efda2a0a3dbe6b353d4",
            "eccede645f12488b89b64a033ff3974b",
            "ebc3bfaa0df54fb4b465a8be5f173c77",
            "43e3b728089f43e08738eb543389f668",
            "501dca2eaa1b413385d2418364c31f4d",
            "1f19bec21c9c4171bb0182a659287b67",
            "81569628f2094766b4cdd304ac353823"
          ]
        },
        "id": "NvrYPNn22tgc",
        "outputId": "e27346e7-93f0-4525-908f-7b55bf171cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Imports done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading /content/cot_dataset/Chain-of-Thought-Cloud.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2502/2502 [00:00<00:00, 322193.01it/s]\n",
            "Loading /content/cot_dataset/Chain-of-Thought-Deep-Learning.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2502/2502 [00:00<00:00, 330774.40it/s]\n",
            "Loading /content/cot_dataset/Chain-of-Thought-DSA.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2502/2502 [00:00<00:00, 310799.60it/s]\n",
            "Loading /content/cot_dataset/Chain-of-Thought-LLM.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2502/2502 [00:00<00:00, 261934.62it/s]\n",
            "Loading /content/cot_dataset/Chain-of-Thought-Machine-Learning.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2502/2502 [00:00<00:00, 260284.45it/s]\n",
            "Loading /content/cot_dataset/Chain-of-Thought-Python.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2533/2533 [00:00<00:00, 264849.48it/s]\n",
            "Loading /content/cot_dataset/Chain-of-Thought-Web.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2085/2085 [00:00<00:00, 250504.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Total unique examples: 9435\n",
            "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b15eefacf37344919620503d6aadff53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e4e1e71679b41bba4ffcd99f6f15063",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/140 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "808b4d509cc44a4495b5d7d43785d38f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b8605ad0efc446b933095c51c2edb86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bfb0fdd07d048c595500f99a9f011e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a8ae4fc29e14f44a63a8b4a6ae3e099",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "728b24fe331a44ce8308ddeac8052e0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f6775dcd2d34eebbf3e8d7cd7f3f491",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/9435 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
            "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
            "Unsloth 2025.12.9 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "# 1ï¸âƒ£ IMPORTS\n",
        "# ======================================================================\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from datasets import Dataset\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "print(\"âœ… Imports done\")\n",
        "\n",
        "# ======================================================================\n",
        "# 2ï¸âƒ£ CONFIGURATION\n",
        "# ======================================================================\n",
        "class Config:\n",
        "    MODEL_NAME = \"microsoft/Phi-3.5-mini-instruct\"\n",
        "    OUTPUT_DIR = \"./phi-mcq-skill-exp-cot\"\n",
        "\n",
        "    DATASET_PATHS = [\n",
        "        \"/content/cot_dataset/Chain-of-Thought-Cloud.json\",\n",
        "        \"/content/cot_dataset/Chain-of-Thought-Deep-Learning.json\",\n",
        "        \"/content/cot_dataset/Chain-of-Thought-DSA.json\",\n",
        "        \"/content/cot_dataset/Chain-of-Thought-LLM.json\",\n",
        "        \"/content/cot_dataset/Chain-of-Thought-Machine-Learning.json\",\n",
        "        \"/content/cot_dataset/Chain-of-Thought-Python.json\",\n",
        "        \"/content/cot_dataset/Chain-of-Thought-Web.json\"\n",
        "    ]\n",
        "\n",
        "    MAX_LENGTH = 1536   # Use larger max length for better coverage\n",
        "    TRAIN_TEST_SPLIT = 0.05\n",
        "\n",
        "    NUM_EPOCHS = 3\n",
        "    BATCH_SIZE = 8\n",
        "    GRAD_ACC = 2\n",
        "\n",
        "    LR = 3e-4\n",
        "    WARMUP = 50\n",
        "    WEIGHT_DECAY = 0.01\n",
        "\n",
        "    # LoRA parameters\n",
        "    LORA_R = 32\n",
        "    LORA_ALPHA = 64\n",
        "    LORA_DROPOUT = 0.05\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# ======================================================================\n",
        "# 3ï¸âƒ£ LOAD + PARSE DATASETS\n",
        "# ======================================================================\n",
        "def parse_input(input_text):\n",
        "    skill, exp = \"General\", \"0-2 years\"\n",
        "    for line in input_text.strip().split(\"\\n\"):\n",
        "        if line.startswith(\"Skills:\"):\n",
        "            skill = line.split(\":\",1)[1].strip()\n",
        "        if line.startswith(\"Experience:\"):\n",
        "            exp = line.split(\":\",1)[1].strip()\n",
        "    return skill, exp\n",
        "\n",
        "def parse_output(output):\n",
        "    try:\n",
        "        mcq = output[\"mcq\"][0]\n",
        "        question = mcq[\"text\"]\n",
        "        explanation = mcq[\"explanation\"]\n",
        "        labels = [\"A\",\"B\",\"C\",\"D\"]\n",
        "\n",
        "        option_dict = {}\n",
        "        correct_label = None\n",
        "        for idx,opt in enumerate(mcq[\"options\"]):\n",
        "            label = labels[idx]\n",
        "            option_dict[label] = opt[\"text\"]\n",
        "            if opt[\"answerType\"]==\"CORRECT\":\n",
        "                correct_label = label\n",
        "\n",
        "        return {\"question\":question, \"options\":option_dict, \"correct_answer\":correct_label, \"explanation\":explanation}\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def load_dataset(path):\n",
        "    with open(path,\"r\",encoding=\"utf-8\") as f:\n",
        "        raw = json.load(f)\n",
        "\n",
        "    parsed = []\n",
        "    seen_questions = set()\n",
        "    for item in tqdm(raw, desc=f\"Loading {path}\"):\n",
        "        skill, exp = parse_input(item[\"input\"])\n",
        "        out = parse_output(item[\"output\"])\n",
        "        if out is None or out[\"question\"] in seen_questions:\n",
        "            continue\n",
        "        seen_questions.add(out[\"question\"])\n",
        "        parsed.append({\n",
        "            \"skill\": skill,\n",
        "            \"experience\": exp,\n",
        "            \"question\": out[\"question\"],\n",
        "            \"A\": out[\"options\"][\"A\"],\n",
        "            \"B\": out[\"options\"][\"B\"],\n",
        "            \"C\": out[\"options\"][\"C\"],\n",
        "            \"D\": out[\"options\"][\"D\"],\n",
        "            \"correct_answer\": out[\"correct_answer\"],\n",
        "            \"explanation\": out[\"explanation\"]\n",
        "        })\n",
        "    return parsed\n",
        "\n",
        "def load_all(paths):\n",
        "    all_data = []\n",
        "    for p in paths:\n",
        "        all_data.extend(load_dataset(p))\n",
        "    print(f\"âœ… Total unique examples: {len(all_data)}\")\n",
        "    return all_data\n",
        "\n",
        "raw_data = load_all(config.DATASET_PATHS)\n",
        "\n",
        "# ======================================================================\n",
        "# 4ï¸âƒ£ PROMPT BUILDER\n",
        "# ======================================================================\n",
        "def build_prompt(ex):\n",
        "    system_msg = \"You are an expert MCQ generator. Generate high-quality questions with one correct answer and detailed explanation.\"\n",
        "    user_msg = f\"\"\"\n",
        "Generate exactly ONE multiple-choice question.\n",
        "\n",
        "Skill: {ex['skill']}\n",
        "Experience Level: {ex['experience']}\n",
        "\n",
        "Output strictly in JSON:\n",
        "{{\n",
        "  \"mcq\": [\n",
        "    {{\n",
        "      \"text\": \"...\",\n",
        "      \"options\": {{\n",
        "        \"A\": \"...\",\n",
        "        \"B\": \"...\",\n",
        "        \"C\": \"...\",\n",
        "        \"D\": \"...\"\n",
        "      }},\n",
        "      \"correct_answer\": \"A/B/C/D\",\n",
        "      \"explanation\": \"...\"\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\"\"\"\n",
        "    assistant = {\n",
        "        \"mcq\":[\n",
        "            {\n",
        "                \"text\": ex[\"question\"],\n",
        "                \"options\": {\"A\": ex[\"A\"], \"B\": ex[\"B\"], \"C\": ex[\"C\"], \"D\": ex[\"D\"]},\n",
        "                \"correct_answer\": ex[\"correct_answer\"],\n",
        "                \"explanation\": ex[\"explanation\"]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return f\"<|system|>\\n{system_msg}<|end|>\\n<|user|>\\n{user_msg}<|end|>\\n<|assistant|>\\n{json.dumps(assistant)}<|end|>\"\n",
        "\n",
        "# ======================================================================\n",
        "# 5ï¸âƒ£ TOKENIZATION\n",
        "# ======================================================================\n",
        "def prepare_dataset(data, tokenizer):\n",
        "    records = [{\"text\": build_prompt(ex)} for ex in data]\n",
        "    ds = Dataset.from_list(records)\n",
        "\n",
        "    def tokenize(batch):\n",
        "        tokenized = tokenizer(\n",
        "            batch[\"text\"],\n",
        "            truncation=True,\n",
        "            max_length=config.MAX_LENGTH,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "        labels = tokenized[\"input_ids\"].copy()\n",
        "        labels = [[(t if t!=tokenizer.pad_token_id else -100) for t in seq] for seq in labels]\n",
        "        tokenized[\"labels\"] = labels\n",
        "        return tokenized\n",
        "\n",
        "    tokenized = ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "    return tokenized.train_test_split(test_size=config.TRAIN_TEST_SPLIT)\n",
        "\n",
        "tokenizer = FastLanguageModel.from_pretrained(config.MODEL_NAME)[1]\n",
        "dataset = prepare_dataset(raw_data, tokenizer)\n",
        "\n",
        "# ======================================================================\n",
        "# 6ï¸âƒ£ LOAD MODEL + LoRA\n",
        "# ======================================================================\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=config.MODEL_NAME,\n",
        "    max_seq_length=config.MAX_LENGTH,\n",
        "    load_in_4bit=True\n",
        ")\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=config.LORA_R,\n",
        "    lora_alpha=config.LORA_ALPHA,\n",
        "    lora_dropout=config.LORA_DROPOUT,\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"]\n",
        ")\n",
        "\n",
        "# ======================================================================\n",
        "# 7ï¸âƒ£ TRAINING ARGUMENTS\n",
        "# ======================================================================\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=config.OUTPUT_DIR,\n",
        "    per_device_train_batch_size=config.BATCH_SIZE,\n",
        "    per_device_eval_batch_size=config.BATCH_SIZE,\n",
        "    gradient_accumulation_steps=config.GRAD_ACC,\n",
        "    learning_rate=config.LR,\n",
        "    num_train_epochs=config.NUM_EPOCHS,\n",
        "    warmup_steps=config.WARMUP,\n",
        "    weight_decay=config.WEIGHT_DECAY,\n",
        "    logging_steps=20,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    save_total_limit=2,\n",
        "    bf16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# ======================================================================\n",
        "# 8ï¸âƒ£ TRAINING\n",
        "# ======================================================================\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    dataset_text_field=None,\n",
        "    max_seq_length=config.MAX_LENGTH,\n",
        "    args=training_args\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Ep4Fvn42teZ",
        "outputId": "c447228e-1f80-4081-d10b-30fe1b7887af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Training started...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 8,963 | Num Epochs = 3 | Total steps = 1,683\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 2\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 2 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 25,165,824 of 3,846,245,376 (0.65% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1683' max='1683' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1683/1683 1:46:42, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.168100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.812600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.590600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.505100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.462000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.440100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.406500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.393800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.374900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.339200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.314200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.304700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.289400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.279000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.235400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.238500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.248400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.235500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.230900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.215300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.195000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.212500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.207300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.196900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.193200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.174400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.198800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.162300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.174300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.202400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.149200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.155900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.174500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.149700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.158500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.150900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.177800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.174800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.160700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.158000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.168400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.172800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.160500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.156800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.165200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.177200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.157600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.161900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.149600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.142000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.143000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.139500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.147900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.144300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.154200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.139400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.124200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.130200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.141400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.131600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.142700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.145000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.145500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.124500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.141800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.127100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.141300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.135100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.132500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.140300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.107600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.147100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>0.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.137400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>0.138100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>0.127400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.126200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>0.128700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.126100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>0.135700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>0.146100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>0.131400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.130300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ‰ Training completed!\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸš€ Training started...\")\n",
        "trainer.train()\n",
        "print(\"ğŸ‰ Training completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "5ALyhxcW2tbT",
        "outputId": "67b5e9bb-4d71-47bf-ca98-7d65e47f204e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
            "Using gradient accumulation will be very slightly less accurate.\n",
            "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Model saved at ./phi-mcq-skill-exp-cot/final_model\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [59/59 00:31]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Eval results: {'eval_loss': 0.1881784349679947, 'eval_runtime': 32.5558, 'eval_samples_per_second': 14.498, 'eval_steps_per_second': 1.812, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "# 9ï¸âƒ£ SAVE MODEL\n",
        "# ======================================================================\n",
        "trainer.save_model(f\"{config.OUTPUT_DIR}/final_model\")\n",
        "tokenizer.save_pretrained(f\"{config.OUTPUT_DIR}/final_model\")\n",
        "print(f\"âœ… Model saved at {config.OUTPUT_DIR}/final_model\")\n",
        "\n",
        "\n",
        "# ======================================================================\n",
        "# EVALUATE\n",
        "# ======================================================================\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"âœ… Eval results: {eval_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "6gviI6o-2tYj",
        "outputId": "bd7a74da-bff9-42d2-8bc0-885f0d65ef9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: phi-mcq-skill-exp-cot/ (stored 0%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/ (stored 0%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/adapter_model.safetensors (deflated 7%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/special_tokens_map.json (deflated 76%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/added_tokens.json (deflated 62%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/adapter_config.json (deflated 56%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/tokenizer_config.json (deflated 86%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/training_args.bin (deflated 53%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/scheduler.pt (deflated 62%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/optimizer.pt (deflated 9%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/chat_template.jinja (deflated 61%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/README.md (deflated 65%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/trainer_state.json (deflated 76%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/tokenizer.model (deflated 55%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/rng_state.pth (deflated 26%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1683/tokenizer.json (deflated 85%)\n",
            "  adding: phi-mcq-skill-exp-cot/README.md (deflated 44%)\n",
            "  adding: phi-mcq-skill-exp-cot/final_model/ (stored 0%)\n",
            "  adding: phi-mcq-skill-exp-cot/final_model/adapter_model.safetensors (deflated 7%)\n",
            "  adding: phi-mcq-skill-exp-cot/final_model/special_tokens_map.json (deflated 76%)\n",
            "  adding: phi-mcq-skill-exp-cot/final_model/added_tokens.json (deflated 62%)\n",
            "  adding: phi-mcq-skill-exp-cot/final_model/adapter_config.json (deflated 56%)\n",
            "  adding: phi-mcq-skill-exp-cot/final_model/tokenizer_config.json (deflated 86%)\n",
            "  adding: phi-mcq-skill-exp-cot/final_model/training_args.bin (deflated 53%)\n",
            "  adding: phi-mcq-skill-exp-cot/final_model/chat_template.jinja (deflated 61%)\n",
            "  adding: phi-mcq-skill-exp-cot/final_model/README.md (deflated 65%)\n",
            "  adding: phi-mcq-skill-exp-cot/final_model/tokenizer.model (deflated 55%)\n",
            "  adding: phi-mcq-skill-exp-cot/final_model/tokenizer.json (deflated 85%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/ (stored 0%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/adapter_model.safetensors (deflated 7%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/special_tokens_map.json (deflated 76%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/added_tokens.json (deflated 62%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/adapter_config.json (deflated 56%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/tokenizer_config.json (deflated 86%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/training_args.bin (deflated 53%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/scheduler.pt (deflated 61%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/optimizer.pt (deflated 9%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/chat_template.jinja (deflated 61%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/README.md (deflated 65%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/trainer_state.json (deflated 76%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/tokenizer.model (deflated 55%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/rng_state.pth (deflated 26%)\n",
            "  adding: phi-mcq-skill-exp-cot/checkpoint-1500/tokenizer.json (deflated 85%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_032eda53-ec7a-4956-860d-26de86371384\", \"phi-mcq-skill-exp-cot.zip\", 648810334)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Download started\n"
          ]
        }
      ],
      "source": [
        "# DOWNLOAD\n",
        "\n",
        "!zip -r phi-mcq-skill-exp-cot.zip {config.OUTPUT_DIR}\n",
        "from google.colab import files\n",
        "files.download(f'phi-mcq-skill-exp-cot.zip')\n",
        "print(\"âœ… Download started\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inference Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "644ua0PY8qiV",
        "outputId": "eb93c790-1471-41e8-91ca-4a2c409e78ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "âœ… Finetuned model loaded!\n"
          ]
        }
      ],
      "source": [
        "# IMPORTS\n",
        "import json\n",
        "import re\n",
        "from unsloth import FastLanguageModel\n",
        "from transformers import TextStreamer\n",
        "import pprint\n",
        "import torch\n",
        "\n",
        "MODEL_PATH = \"/content/phi-mcq-skill-exp-cot/final_model\"\n",
        "\n",
        "# Load model + tokenizer\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=MODEL_PATH,\n",
        "    max_seq_length=1536,\n",
        "    load_in_4bit=True\n",
        ")\n",
        "\n",
        "print(\"âœ… Finetuned model loaded!\")\n",
        "\n",
        "# =========================\n",
        "# CLEAN OUTPUT\n",
        "# =========================\n",
        "def clean_output(text):\n",
        "    text = text.replace(\"<|assistant|>\", \"\").strip()\n",
        "    return text\n",
        "\n",
        "# =========================\n",
        "# BUILD PROMPT FOR CHAIN-OF-THOUGHT\n",
        "# =========================\n",
        "def build_prompt(skill=\"Python\", experience=\"0-2 years\"):\n",
        "    return f\"\"\"\n",
        "You are an expert MCQ generator.\n",
        "First, write your step-by-step reasoning in natural language about how you will create the MCQ for:\n",
        "Skill: {skill}, Experience: {experience}.\n",
        "\n",
        "Explain:\n",
        "1. Which concept or topic to test.\n",
        "2. How to phrase the question clearly.\n",
        "3. How to create plausible distractors.\n",
        "4. How to determine the correct answer and why.\n",
        "\n",
        "After your reasoning, output exactly one multiple-choice question in JSON format:\n",
        "\n",
        "[Reasoning]\n",
        "Your step-by-step explanation goes here.\n",
        "\n",
        "[MCQ JSON]\n",
        "{{\n",
        "  \"mcq\": [\n",
        "    {{\n",
        "      \"text\": \"...\",\n",
        "      \"options\": {{\"A\": \"...\",\"B\": \"...\",\"C\": \"...\",\"D\": \"...\" }},\n",
        "      \"correct_answer\": \"A/B/C/D\",\n",
        "      \"explanation\": \"...\"\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "# =========================\n",
        "# GENERATE SINGLE MCQ WITH REASONING\n",
        "# =========================\n",
        "def generate_mcq_with_reasoning(skill=\"Python\", experience=\"0-2 years\"):\n",
        "    prompt = build_prompt(skill, experience)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Dynamically set max_new_tokens to avoid truncation\n",
        "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
        "    max_tokens = prompt_len + 512  # 512 tokens for reasoning + MCQ\n",
        "    max_tokens = min(max_tokens, 2048)  # avoid excessive memory usage\n",
        "\n",
        "    # Generate output with sampling\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_tokens,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.1,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "    # Decode the generated text\n",
        "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    decoded = clean_output(decoded)\n",
        "\n",
        "    return decoded\n",
        "\n",
        "# =========================\n",
        "# GENERATE N MCQs\n",
        "# =========================\n",
        "def generate_n_mcqs(n=5, skill=\"Python\", experience=\"0-2 years\"):\n",
        "    results = []\n",
        "    for i in range(n):\n",
        "        print(f\"\\n=== Generating MCQ {i+1}/{n} ===\")\n",
        "        mcq_text = generate_mcq_with_reasoning(skill, experience)\n",
        "        print(\"\\n--- Model Reasoning + MCQ ---\\n\", mcq_text)\n",
        "        results.append(mcq_text)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24LWHuw3W_cN",
        "outputId": "b025fbaf-784a-4ed4-bdcb-76be9325d5dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Generating MCQ 1/5 ===\n",
            "\n",
            "--- Model Reasoning + MCQ ---\n",
            " You are an expert MCQ generator. \n",
            "First, write your step-by-step reasoning in natural language about how you will create the MCQ for:\n",
            "Skill: Python/LLM, Experience: 5 years.\n",
            "\n",
            "Explain:\n",
            "1. Which concept or topic to test.\n",
            "2. How to phrase the question clearly.\n",
            "3. How to create plausible distractors.\n",
            "4. How to determine the correct answer and why.\n",
            "\n",
            "After your reasoning, output exactly one multiple-choice question in JSON format:\n",
            "\n",
            "[Reasoning]\n",
            "Your step-by-step explanation goes here.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"...\",\n",
            "      \"options\": {\"A\": \"...\",\"B\": \"...\",\"C\": \"...\",\"D\": \"...\" },\n",
            "      \"correct_answer\": \"A/B/C/D\",\n",
            "      \"explanation\": \"...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            " [Reasoning]\n",
            "To test understanding of decorators (a key feature used extensively throughout a typical LLM stack), I'll choose a scenario where users need to apply such knowledge practically. The goal is to assess whether they can identify when and how to use various types of decorators available in Python.\n",
            "\n",
            "Question Text: In `fastapi`, which class should be extended from `uvicorn` to build a server that automatically reloads code changes?\n",
            "\n",
            "Options:\n",
            "A) FastAPI itself with `@reloadable`\n",
            "B) Uvicorn directly by subclassing it (`MyUvicornServer`)\n",
            "C) By using Flask instead\n",
            "D) Directly calling uvicorn without inheritance\n",
            "\n",
            "Correct Answer: B) Uvicorn directly by subclassing it (`MyUvicornServer`) - This requires knowing what classes exist within libraries like this one and their relationship to runtime behavior.\n",
            "Explanation: Subclassing allows customizing existing functionalityâ€”here, adding automatic reload capability on file change detection during development.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"In a production environment, fastapi runs on Gunicorn behind Nginx.\",\n",
            "      \"options\": {\"A\": \"Gunicron + Nginx\", \"B\": \"Nginx alone\", \"C\": \"Apache\", \"D\": \"FastAPI handles everything\"},\n",
            "      \"correct_answer\": \"A\",\n",
            "      \"explanation\": \"Production setups typically use something like Gunicorn as the application server and Nginx as a reverse proxy.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "=== Generating MCQ 2/5 ===\n",
            "\n",
            "--- Model Reasoning + MCQ ---\n",
            " You are an expert MCQ generator. \n",
            "First, write your step-by-step reasoning in natural language about how you will create the MCQ for:\n",
            "Skill: Python/LLM, Experience: 5 years.\n",
            "\n",
            "Explain:\n",
            "1. Which concept or topic to test.\n",
            "2. How to phrase the question clearly.\n",
            "3. How to create plausible distractors.\n",
            "4. How to determine the correct answer and why.\n",
            "\n",
            "After your reasoning, output exactly one multiple-choice question in JSON format:\n",
            "\n",
            "[Reasoning]\n",
            "Your step-by-step explanation goes here.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"...\",\n",
            "      \"options\": {\"A\": \"...\",\"B\": \"...\",\"C\": \"...\",\"D\": \"...\" },\n",
            "      \"correct_answer\": \"A/B/C/D\",\n",
            "      \"explanation\": \"...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            " [Reasoning]\n",
            "To test deep understanding of LLMs, we'll focus on 'Feedback Loops' (how users interact with the model and how those interactions improve the model over time). The question will target the theoretical foundation rather than implementation details.\n",
            "\n",
            "Step 1: Identify a core concept related to feedback loops in AI systems.\n",
            "Step 2: Craft a question that probes understanding of this concept at a high level.\n",
            "Step 3: Create realistic incorrect answers based on common misconceptions.\n",
            "Step 4: Justify the correct answer by linking it back to established theory.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"In an RLF loop (Reinforcement Learning Feedback), what is the primary signal used to guide agent behavior?\",\n",
            "      \"options\": {\n",
            "        \"A\": \"The reward signal received after taking an action.\",\n",
            "        \"B\": \"Random noise injected into the system.\",\n",
            "        \"C\": \"The immediate state transition without any gradient.\",\n",
            "        \"D\": \"Gradient information derived from the policy.\"\n",
            "      },\n",
            "      \"correct_answer\": \"A\",\n",
            "      \"explanation\": \"RL uses rewards to reinforce desirable behaviors, guiding agents through trial and error.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "=== Generating MCQ 3/5 ===\n",
            "\n",
            "--- Model Reasoning + MCQ ---\n",
            " You are an expert MCQ generator. \n",
            "First, write your step-by-step reasoning in natural language about how you will create the MCQ for:\n",
            "Skill: Python/LLM, Experience: 5 years.\n",
            "\n",
            "Explain:\n",
            "1. Which concept or topic to test.\n",
            "2. How to phrase the question clearly.\n",
            "3. How to create plausible distractors.\n",
            "4. How to determine the correct answer and why.\n",
            "\n",
            "After your reasoning, output exactly one multiple-choice question in JSON format:\n",
            "\n",
            "[Reasoning]\n",
            "Your step-by-step explanation goes here.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"...\",\n",
            "      \"options\": {\"A\": \"...\",\"B\": \"...\",\"C\": \"...\",\"D\": \"...\" },\n",
            "      \"correct_answer\": \"A/B/C/D\",\n",
            "      \"explanation\": \"...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            " [Reasoning]\n",
            "To test deep understanding of LLMs at the intersection of AI and software engineering, we should focus on algorithmic complexity within neural networks. The specific application is optimizing search algorithms used in large datasets typical in web applications.\n",
            "\n",
            "Question: When designing a search engine backend, which optimization technique helps reduce time complexity by eliminating nodes that must be explored because their subproblems overlap with already solved subproblems?\n",
            "\n",
            "Options:\n",
            "A) Greedy best-first search\n",
            "B) Dynamic programming exclusively\n",
            "C) Dijkstra's algorithm without heuristics\n",
            "D) **Memoization** (Dynamic Programming), where previously computed results are stored and reused when needed again.\n",
            "\n",
            "Correct Answer: D\n",
            "Explanation: Memoization reduces redundant calculations by storing previous computation results; this characteristic defines dynamic programming methods applied to graph traversal problems like searching engines backends.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"In complex networked systems such as online retail platforms, what strategy minimizes pathfinding computations through repeated evaluation of identical subproblem instances?\",\n",
            "      \"options\": {\"A\": \"Randomized greedy strategies only.\", \"B\": \"Iterative improvement via hill climbing techniques alone.\", \"C\": \"Applying memoization principles from dynamic programming approaches consistently.\", \"D\": \"Using simple breadth-first search everywhere.\"},\n",
            "      \"correct_answer\": \"C\",\n",
            "      \"explanation\": \"By applying 'memoization', repetitive work done during recursive calls can be avoided since past states have been visited before reaching current state â€“ reducing overall computational cost significantly.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "=== Generating MCQ 4/5 ===\n",
            "\n",
            "--- Model Reasoning + MCQ ---\n",
            " You are an expert MCQ generator. \n",
            "First, write your step-by-step reasoning in natural language about how you will create the MCQ for:\n",
            "Skill: Python/LLM, Experience: 5 years.\n",
            "\n",
            "Explain:\n",
            "1. Which concept or topic to test.\n",
            "2. How to phrase the question clearly.\n",
            "3. How to create plausible distractors.\n",
            "4. How to determine the correct answer and why.\n",
            "\n",
            "After your reasoning, output exactly one multiple-choice question in JSON format:\n",
            "\n",
            "[Reasoning]\n",
            "Your step-by-step explanation goes here.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"...\",\n",
            "      \"options\": {\"A\": \"...\",\"B\": \"...\",\"C\": \"...\",\"D\": \"...\" },\n",
            "      \"correct_answer\": \"A/B/C/D\",\n",
            "      \"explanation\": \"...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            " [Reasoning]\n",
            "1. Topic: Functional programming paradigm (Pure functions).\n",
            "2. Question focuses on distinguishing pure from impure functions based on side effects.\n",
            "3. Distractor options include subtle misconceptions about purity.\n",
            "4. The correct answer is defined by whether a function has any observable side effects other than returning its input.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"What characterizes a **pure function**?\\n\\nA) It always modifies global state.\\nB) Its return value depends only on its input values.\",\n",
            "      \"options\": {\"A\": \"It may have external dependencies like I/O operations.\", \"B\": \"Its behavior can change depending on when it's called.\", \"C\": \"No visible interaction with outside world except inputs.\", \"D\": \"The result changes if the same arguments are passed.\"},\n",
            "      \"correct_answer\": \"B\",\n",
            "      \"explanation\": \"In functional programming, a function is considered pure if changing parameters doesnâ€™t affect anything else; this predictability makes testing easier.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "=== Generating MCQ 5/5 ===\n",
            "\n",
            "--- Model Reasoning + MCQ ---\n",
            " You are an expert MCQ generator. \n",
            "First, write your step-by-step reasoning in natural language about how you will create the MCQ for:\n",
            "Skill: Python/LLM, Experience: 5 years.\n",
            "\n",
            "Explain:\n",
            "1. Which concept or topic to test.\n",
            "2. How to phrase the question clearly.\n",
            "3. How to create plausible distractors.\n",
            "4. How to determine the correct answer and why.\n",
            "\n",
            "After your reasoning, output exactly one multiple-choice question in JSON format:\n",
            "\n",
            "[Reasoning]\n",
            "Your step-by-step explanation goes here.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"...\",\n",
            "      \"options\": {\"A\": \"...\",\"B\": \"...\",\"C\": \"...\",\"D\": \"...\" },\n",
            "      \"correct_answer\": \"A/B/C/D\",\n",
            "      \"explanation\": \"...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            " [Reasoning]\n",
            "To test deep understanding of LLMs in Python, we'll focus on 'Error Handling and Debugging'. This is a critical skill as error handling often determines the robustness of an application.\n",
            "\n",
            "Step 1: Choose a specific type of exception (e.g., `ConnectionRefusedError`) relevant to web applications but not too common so that memorization isn't favored over understanding.\n",
            "\n",
            "Step 2: Formulate the question around identifying the best practice when such an error occursâ€”for example, checking network connectivity before retrying, which demonstrates good debugging practices like isolating issues.\n",
            "\n",
            "Step 3: Create realistic options including both technical details and general Python principles (like using context managers).\n",
            "\n",
            "Step 4: The correct answer should highlight standard procedure during unexpected errors while testing infrastructure.\n",
            "\n",
            "Output strictly one MCQ.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"When encountering `ConnectionRefusedError` during unit tests of a web app, what is the most appropriate next step?\",\n",
            "      \"options\": {\n",
            "        \"A\": \"Restart the entire server immediately.\",\n",
            "        \"B\": \"Check if the database connection string is incorrect; otherwise, check network connectivity by pinging the service endpoint with minimal payload.\"\n",
            "      },\n",
            "      \"correct_answer\": \"B\",\n",
            "      \"explanation\": \"Debugging involves narrowing down the cause systematically starting from basic checks (network vs faulty credentials) rather than making broad assumptions like immediate restarts without diagnostics.\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# EXAMPLE USAGE\n",
        "# =========================\n",
        "# Adjust the skill and experience as needed\n",
        "mcqs = generate_n_mcqs(n=5, skill=\"Python/LLM\", experience=\"5 years\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7h8_PzqZnqk",
        "outputId": "f6233b36-d81b-486c-9b75-c7f064b9a701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Generating MCQ 1/5 ===\n",
            "\n",
            "--- Model Reasoning + MCQ ---\n",
            " You are an expert MCQ generator. \n",
            "First, write your step-by-step reasoning in natural language about how you will create the MCQ for:\n",
            "Skill: DL/Cloud, Experience: 15 years.\n",
            "\n",
            "Explain:\n",
            "1. Which concept or topic to test.\n",
            "2. How to phrase the question clearly.\n",
            "3. How to create plausible distractors.\n",
            "4. How to determine the correct answer and why.\n",
            "\n",
            "After your reasoning, output exactly one multiple-choice question in JSON format:\n",
            "\n",
            "[Reasoning]\n",
            "Your step-by-step explanation goes here.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"...\",\n",
            "      \"options\": {\"A\": \"...\",\"B\": \"...\",\"C\": \"...\",\"D\": \"...\" },\n",
            "      \"correct_answer\": \"A/B/C/D\",\n",
            "      \"explanation\": \"...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            " [Reasoning]\n",
            "To test deep learning and cloud skills at a high level, we should focus on architectural decisions rather than implementation details. The question should assess understanding of trade-offs between different system designs.\n",
            "\n",
            "Text: When designing a distributed caching system, which choice best balances consistency with user experience?\n",
            "\n",
            "Options:\n",
            "A) Prioritize eventual consistency (cache invalidation) over strict ACID transactions.\n",
            "B) Use strong consistency everywhere to ensure data integrity.\n",
            "C) Optimize for latency minimization using approximate consistency models.\n",
            "D) Eliminate cache layers entirely to guarantee absolute consistency.\n",
            "\n",
            "Correct Answer: A) Eventual consistency is often preferred in caching systems because it provides a good balance between availability and user experience while tolerating minor data divergence.\n",
            "Explanation: In large distributed systems like caches, perfect consistency can be too costly performance-wise; hence, eventually consistent replication is standard practice.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"When prioritizing consistency vs. user experience in caching system design, what is generally accepted?\",\n",
            "      \"options\": {\"A\": \"Eventually consistent replicas favor user experience.\", \"B\": \"Strong consistency must always be sacrificed for speed.\", \"C\": \"Use approximations to reduce complexity without severely impacting users.\", \"D\": \"Absolute consistency trumps all other concerns.\"},\n",
            "      \"correct_answer\": \"A\",\n",
            "      \"explanation\": \"In many real-world distributed caching scenarios, giving up some degree of immediate consistency helps achieve lower latency and better user experiences by leveraging heuristic optimizations.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "=== Generating MCQ 2/5 ===\n",
            "\n",
            "--- Model Reasoning + MCQ ---\n",
            " You are an expert MCQ generator. \n",
            "First, write your step-by-step reasoning in natural language about how you will create the MCQ for:\n",
            "Skill: DL/Cloud, Experience: 15 years.\n",
            "\n",
            "Explain:\n",
            "1. Which concept or topic to test.\n",
            "2. How to phrase the question clearly.\n",
            "3. How to create plausible distractors.\n",
            "4. How to determine the correct answer and why.\n",
            "\n",
            "After your reasoning, output exactly one multiple-choice question in JSON format:\n",
            "\n",
            "[Reasoning]\n",
            "Your step-by-step explanation goes here.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"...\",\n",
            "      \"options\": {\"A\": \"...\",\"B\": \"...\",\"C\": \"...\",\"D\": \"...\" },\n",
            "      \"correct_answer\": \"A/B/C/D\",\n",
            "      \"explanation\": \"...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            " [Reasoning]\n",
            "For a senior cloud engineer, we should focus on deep architecture decisions rather than basic concepts. The question should evaluate understanding of trade-offs between different architectural styles (e.g., vs.).\n",
            "\n",
            "Text: When designing a cloud application around data workloads, which pattern best balances latency with throughput?\n",
            "\n",
            "Options:\n",
            "A) Purely stateless services with eventual consistency.\n",
            "B) Single replica without auto-scaling.\n",
            "C) Cached read model optimized for low latency.\n",
            "D) Exclusively using database transactions.\n",
            "\n",
            "Correct Answer: A) Purely stateless services with eventual consistency allow horizontal scaling while managing latency via caching strategies.\n",
            "Explanation: Stateless designs paired with effective cache layers provide scalability and manageable latencyâ€”a common goal when building systems designed for large numbers of users.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"When optimizing for high availability in system xyxvz, what is generally accepted as necessary regardless of specific technology?\"\n",
            "      \"options\": {\n",
            "        \"A\": \"Redundant independent components.\",\n",
            "        \"B\": \"Using only primary nodes without failures.\",\n",
            "        \"C\": \"Failover mechanisms that detect node outages and reroute traffic accordingly.\",\n",
            "        \"D\": \"Ignoring load balancers.\"\n",
            "      },\n",
            "      \"correct_answer\": \"C\",\n",
            "      \"explanation\": \"High availability requires redundancy so if one component fails, others can take over its tasks seamlessly.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "=== Generating MCQ 3/5 ===\n",
            "\n",
            "--- Model Reasoning + MCQ ---\n",
            " You are an expert MCQ generator. \n",
            "First, write your step-by-step reasoning in natural language about how you will create the MCQ for:\n",
            "Skill: DL/Cloud, Experience: 15 years.\n",
            "\n",
            "Explain:\n",
            "1. Which concept or topic to test.\n",
            "2. How to phrase the question clearly.\n",
            "3. How to create plausible distractors.\n",
            "4. How to determine the correct answer and why.\n",
            "\n",
            "After your reasoning, output exactly one multiple-choice question in JSON format:\n",
            "\n",
            "[Reasoning]\n",
            "Your step-by-step explanation goes here.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"...\",\n",
            "      \"options\": {\"A\": \"...\",\"B\": \"...\",\"C\": \"...\",\"D\": \"...\" },\n",
            "      \"correct_answer\": \"A/B/C/D\",\n",
            "      \"explanation\": \"...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            " [Reasoning]\n",
            "For a senior cloud engineer, we should focus on advanced distributed system concepts like consistent hashing, which is crucial for scalable hash tables across nodes. The question should assess deep understanding rather than surface knowledge.\n",
            "\n",
            "Step 1: Identify core theoretical concept (consistent hashing).\n",
            "Step 2: Formulate clear question around application of theory.\n",
            "Step 3: Create realistic distractors based on common misconceptions.\n",
            "Step 4: Determine correct answer by comparing against best practices in distributed systems.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"In large distributed key-value stores using consistent hashing, each node is responsible for storing keys that fall within which range?\",\n",
            "      \"options\": {\n",
            "        \"A\": \"The entire range of keys.\",\n",
            "        \"B\": \"Keys mapped directly under its assigned virtual node number.\",\n",
            "        \"C\": \"Only keys explicitly requested by clients.\",\n",
            "        \"D\": A specific predefined range determined by the hash function.\"\n",
            "      },\n",
            "      \"correct_answer\": \"B\",\n",
            "      \"explanation\": \"Consistent hashing maps keys to virtual node numbers, so each node handles keys whose hash values fall within its assigned range.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "=== Generating MCQ 4/5 ===\n",
            "\n",
            "--- Model Reasoning + MCQ ---\n",
            " You are an expert MCQ generator. \n",
            "First, write your step-by-step reasoning in natural language about how you will create the MCQ for:\n",
            "Skill: DL/Cloud, Experience: 15 years.\n",
            "\n",
            "Explain:\n",
            "1. Which concept or topic to test.\n",
            "2. How to phrase the question clearly.\n",
            "3. How to create plausible distractors.\n",
            "4. How to determine the correct answer and why.\n",
            "\n",
            "After your reasoning, output exactly one multiple-choice question in JSON format:\n",
            "\n",
            "[Reasoning]\n",
            "Your step-by-step explanation goes here.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"...\",\n",
            "      \"options\": {\"A\": \"...\",\"B\": \"...\",\"C\": \"...\",\"D\": \"...\" },\n",
            "      \"correct_answer\": \"A/B/C/D\",\n",
            "      \"explanation\": \"...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            " [Reasoning]\n",
            "To test deep learning and cloud experience:\n",
            "1. Choose a complex but common pattern (e.g., distributed training).\n",
            "2. Craft the question around implementing this pattern correctly.\n",
            "3. Create realistic incorrect answers that represent common misunderstandings.\n",
            "4. Select the correct answer based on best practices.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"When deploying models to edge devices, which practice is most important?\",\n",
            "      \"options\": {\"A\": \"Ignoring resource constraints since CPU limits don't matter.\", \"B\": \"Balancing model complexity with hardware capabilities (latency, power) rather than just FLOPS.\", \"C\": \"Using only high-precision floating-point operations regardless of performance.\", \"D\": \"Forcing all layers to be fully connected.\"},\n",
            "      \"correct_answer\": \"B\",\n",
            "      \"explanation\": \"Efficient use of resources involves selecting algorithms and model architectures that match device specifications while maintaining quality.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "=== Generating MCQ 5/5 ===\n",
            "\n",
            "--- Model Reasoning + MCQ ---\n",
            " You are an expert MCQ generator. \n",
            "First, write your step-by-step reasoning in natural language about how you will create the MCQ for:\n",
            "Skill: DL/Cloud, Experience: 15 years.\n",
            "\n",
            "Explain:\n",
            "1. Which concept or topic to test.\n",
            "2. How to phrase the question clearly.\n",
            "3. How to create plausible distractors.\n",
            "4. How to determine the correct answer and why.\n",
            "\n",
            "After your reasoning, output exactly one multiple-choice question in JSON format:\n",
            "\n",
            "[Reasoning]\n",
            "Your step-by-step explanation goes here.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"...\",\n",
            "      \"options\": {\"A\": \"...\",\"B\": \"...\",\"C\": \"...\",\"D\": \"...\" },\n",
            "      \"correct_answer\": \"A/B/C/D\",\n",
            "      \"explanation\": \"...\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            " [Reasoning]\n",
            "For a senior cloud engineer, we should focus on advanced distributed system concepts like consistent hashing across regions or dynamic scaling strategies. The question should evaluate deep understanding rather than surface knowledge.\n",
            "\n",
            "Step 1: Identify the core skill and relevant subtopic (e.g., designing scalable hashing schemes).\n",
            "Step 2: Formulate a scenario that requires applying theoretical knowledge to practical problem solving.\n",
            "Step 3: Craft one correct answer based on best practices from literature/blogs of respected engineers.\n",
            "Step 4: Create three incorrect answers that sound feasible but contain subtle flaws when applied generally.\n",
            "\n",
            "Output strictly one MCQ.\n",
            "\n",
            "[MCQ JSON]\n",
            "{\n",
            "  \"mcq\": [\n",
            "    {\n",
            "      \"text\": \"When deploying application N where K is number of partitions with replication R=R+N, which statement correctly describes data distribution?\",\n",
            "      \"options\": {\n",
            "        \"A\": \"Each partition contains only one shard.\",\n",
            "        \"B\": \"Data is randomly scattered without any pattern.\",\n",
            "        \"C\": \"Replicated copies exist within each region; primary nodes handle writes while read traffic may be directed at secondary instances.\",\n",
            "        \"D\": \"The database schema must match the exact structure of Aries.\"\n",
            "      },\n",
            "      \"correct_answer\": \"C\",\n",
            "      \"explanation\": \"In high availability systems, redundant backups ensure service continuity despite failures.\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# EXAMPLE USAGE\n",
        "# =========================\n",
        "# Adjust the skill and experience as needed\n",
        "mcqs = generate_n_mcqs(n=5, skill=\"DL/Cloud\", experience=\"15 years\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RjbqQZaHr6q"
      },
      "source": [
        "### DPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHD9gOe4HvOb"
      },
      "outputs": [],
      "source": [
        "# ======================================================================\n",
        "# 1ï¸âƒ£ IMPORTS\n",
        "# ======================================================================\n",
        "import json\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import DPOTrainer, DPOConfig\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from deepeval import evaluate\n",
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.metrics import (\n",
        "    AnswerRelevancyMetric,\n",
        "    FaithfulnessMetric,\n",
        "    BiasMetric,\n",
        ")\n",
        "\n",
        "print(\"âœ… Imports Ready\")\n",
        "\n",
        "# ======================================================================\n",
        "# 2ï¸âƒ£ CONFIG\n",
        "# ======================================================================\n",
        "BASE_MODEL = \"/content/phi-mcq-skill-exp-cot/final_model\"\n",
        "OUTPUT_DIR = \"/content/phi-mcq-skill-exp-cot-dpo\"\n",
        "\n",
        "DPO_DATASET = [\n",
        "    \"/content/dpo_dataset/0-15+_Cloud_Services_DPO.json\",\n",
        "    \"/content/dpo_dataset/0-15+_DSA_DPO.json\",\n",
        "    \"/content/dpo_dataset/0-15+_Deep_Learning_DPO.json\",\n",
        "    \"/content/dpo_dataset/0-15+_LLM_DPO.json\",\n",
        "    \"/content/dpo_dataset/0-15+_ML_DPO.json\",\n",
        "    \"/content/dpo_dataset/0-15+_Python_DPO.json\",\n",
        "    \"/content/dpo_dataset/0-15+_Web_DPO.json\",\n",
        "]\n",
        "\n",
        "SAMPLES_PER_SKILL = 300\n",
        "SEED = 42\n",
        "\n",
        "# ======================================================================\n",
        "# 3ï¸âƒ£ HELPERS\n",
        "# ======================================================================\n",
        "def serialize_output(output_obj):\n",
        "    return json.dumps(output_obj, ensure_ascii=False)\n",
        "\n",
        "def build_prompt(chosen_obj):\n",
        "    instruction = chosen_obj.get(\"instruction\", \"\").strip()\n",
        "    input_text = chosen_obj.get(\"input\", \"\").strip()\n",
        "    return f\"{instruction}\\n\\n{input_text}\".strip()\n",
        "\n",
        "# ======================================================================\n",
        "# 4ï¸âƒ£ LOAD & PREPARE DATASET\n",
        "# ======================================================================\n",
        "all_datasets = []\n",
        "\n",
        "for file_path in DPO_DATASET:\n",
        "    print(f\"ğŸ“‚ Loading {file_path}\")\n",
        "    ds = load_dataset(\"json\", data_files=file_path, split=\"train\")\n",
        "\n",
        "    if len(ds) < SAMPLES_PER_SKILL:\n",
        "        raise ValueError(f\"{file_path} has only {len(ds)} samples\")\n",
        "\n",
        "    ds = ds.shuffle(seed=SEED).select(range(SAMPLES_PER_SKILL))\n",
        "\n",
        "    def transform(example):\n",
        "        return {\n",
        "            \"prompt\": build_prompt(example[\"chosen\"]),\n",
        "            \"chosen\": serialize_output(example[\"chosen\"][\"output\"]),\n",
        "            \"rejected\": serialize_output(example[\"rejected\"][\"output\"]),\n",
        "        }\n",
        "\n",
        "    ds = ds.map(transform, remove_columns=ds.column_names)\n",
        "    all_datasets.append(ds)\n",
        "\n",
        "dpo_dataset = concatenate_datasets(all_datasets)\n",
        "print(f\"ğŸ”¥ Total DPO samples: {len(dpo_dataset)}\")\n",
        "\n",
        "# ======================================================================\n",
        "# 5ï¸âƒ£ TRAIN / EVAL SPLIT\n",
        "# ======================================================================\n",
        "dpo_dataset = dpo_dataset.shuffle(seed=SEED)\n",
        "split = dpo_dataset.train_test_split(test_size=0.05, seed=SEED)\n",
        "\n",
        "train_dataset = split[\"train\"]\n",
        "eval_dataset = split[\"test\"]\n",
        "\n",
        "print(f\"ğŸ“Š Train: {len(train_dataset)} | Eval: {len(eval_dataset)}\")\n",
        "\n",
        "# ======================================================================\n",
        "# 6ï¸âƒ£ LOAD MODEL & TOKENIZER\n",
        "# ======================================================================\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    max_seq_length=1536,\n",
        "    load_in_4bit=True,\n",
        "    dtype=None,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "tokenizer.padding_side = \"right\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "model = FastLanguageModel.for_training(model)\n",
        "\n",
        "# ======================================================================\n",
        "# 7ï¸âƒ£ LOAD REFERENCE MODEL (FROZEN)\n",
        "# ======================================================================\n",
        "ref_model, _ = FastLanguageModel.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    max_seq_length=1536,\n",
        "    load_in_4bit=True,\n",
        "    dtype=None,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "ref_model = FastLanguageModel.for_training(ref_model)\n",
        "ref_model.eval()\n",
        "for p in ref_model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "print(\"ğŸ“Œ Model & Reference Model Loaded\")\n",
        "\n",
        "# ======================================================================\n",
        "# 8ï¸âƒ£ DPO CONFIG\n",
        "# ======================================================================\n",
        "dpo_config = DPOConfig(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=1,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=1e-6,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_steps=200,\n",
        "    weight_decay=0.01,\n",
        "    save_steps=500,\n",
        "    logging_steps=20,\n",
        "    save_total_limit=2,\n",
        "    bf16=torch.cuda.is_bf16_supported(),\n",
        "    fp16=not torch.cuda.is_bf16_supported(),\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    max_grad_norm=0.1,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\",\n",
        "    beta=0.05,\n",
        "    loss_type=\"ipo\",\n",
        "    max_length=1536,\n",
        "    max_prompt_length=512,\n",
        ")\n",
        "\n",
        "# ======================================================================\n",
        "# 9ï¸âƒ£ DPO TRAINER\n",
        "# ======================================================================\n",
        "trainer = DPOTrainer(\n",
        "    model=model,\n",
        "    ref_model=ref_model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    args=dpo_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLtzGzPkH9ti"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "trainer.train()\n",
        "print(\"âœ… DPO Training Complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm3FRjIQIVX3"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(f\"{OUTPUT_DIR}/final_model\")\n",
        "tokenizer.save_pretrained(f\"{OUTPUT_DIR}/final_model\")\n",
        "\n",
        "print(f\"âœ… Model saved at {OUTPUT_DIR}/final_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZejCHL46IYCe"
      },
      "outputs": [],
      "source": [
        "# DOWNLOAD\n",
        "\n",
        "!zip -r phi-mcq-skill-exp-cot-dpo.zip {OUTPUT_DIR}\n",
        "from google.colab import files\n",
        "files.download(f'phi-mcq-skill-exp-cot-dpo.zip')\n",
        "print(\"âœ… Download started\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdlqidpWIdSL"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import json\n",
        "import re\n",
        "from unsloth import FastLanguageModel\n",
        "from transformers import TextStreamer\n",
        "import pprint\n",
        "\n",
        "MODEL_PATH = \"/content/phi-mcq-skill-exp-cot-dpo/final_model\"\n",
        "\n",
        "# Load model + tokenizer\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=MODEL_PATH,\n",
        "    max_seq_length=1536,\n",
        "    load_in_4bit=True\n",
        ")\n",
        "\n",
        "print(\"âœ… Finetuned model loaded!\")\n",
        "\n",
        "# PROMPT BUILDER\n",
        "def build_prompt(skill, experience):\n",
        "    system_msg = \"You are an expert MCQ generator. Create high-quality multiple-choice questions with one correct answer and detailed explanation.\"\n",
        "    user_msg = f\"\"\"\n",
        "Generate exactly ONE multiple-choice question.\n",
        "\n",
        "Skill: {skill}\n",
        "Experience Level: {experience}\n",
        "\n",
        "Output strictly in JSON:\n",
        "{{\n",
        "  \"mcq\": [\n",
        "    {{\n",
        "      \"text\": \"...\",\n",
        "      \"options\": {{\n",
        "        \"A\": \"...\",\n",
        "        \"B\": \"...\",\n",
        "        \"C\": \"...\",\n",
        "        \"D\": \"...\"\n",
        "      }},\n",
        "      \"correct_answer\": \"A/B/C/D\",\n",
        "      \"explanation\": \"...\"\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\"\"\"\n",
        "    return f\"<|system|>\\n{system_msg}<|end|>\\n<|user|>\\n{user_msg}<|end|>\\n<|assistant|>\\n\"\n",
        "\n",
        "# CLEAN OUTPUT\n",
        "def clean_output(text):\n",
        "    # Remove all Phi special tokens like <|end|> etc.\n",
        "    text = re.sub(r\"<\\|.*?\\|>\", \"\", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "# GENERATE SINGLE MCQ\n",
        "def generate_mcq(skill=\"Python\", experience=\"0-2 years\"):\n",
        "    prompt = build_prompt(skill, experience)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    eos_id = tokenizer.convert_tokens_to_ids(\"<|end|>\")\n",
        "\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=400,\n",
        "        temperature=0.4,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        repetition_penalty=1.1,\n",
        "        eos_token_id=eos_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.decode(output[0])\n",
        "    if \"<|assistant|>\" in decoded:\n",
        "        decoded = decoded.split(\"<|assistant|>\")[-1]\n",
        "\n",
        "    return clean_output(decoded)\n",
        "\n",
        "# GENERATE N UNIQUE MCQs\n",
        "def generate_n_mcqs(n=10, skill=\"Python\", experience=\"0-2 years\"):\n",
        "    results = []\n",
        "    seen_questions = set()\n",
        "\n",
        "    for i in range(n):\n",
        "        print(f\"\\n=== Generating MCQ {i+1}/{n} ===\\n\")\n",
        "        while True:\n",
        "            mcq = generate_mcq(skill, experience)\n",
        "            # Try to extract the question text to avoid duplicates\n",
        "            try:\n",
        "                mcq_json = json.loads(mcq)\n",
        "                question_text = mcq_json[\"mcq\"][0][\"text\"]\n",
        "            except:\n",
        "                continue  # Retry if JSON is invalid\n",
        "\n",
        "            if question_text not in seen_questions:\n",
        "                seen_questions.add(question_text)\n",
        "                results.append(mcq)\n",
        "                pprint.pprint(mcq)\n",
        "                break  # move to next MCQ\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjYl9xQLIgyL"
      },
      "outputs": [],
      "source": [
        "# USAGE\n",
        "# Example: Generate 10 MCQs for Python, 0-2 years experience\n",
        "mcqs = generate_n_mcqs(n=10, skill=\"Data Analysis\", experience=\"2-5 years\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05ce92be53854e3eac5050c08e639622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09f511ebba334065812f785d1c4bcad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c068acf5c8441da8ad8c62028f0c5a2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_70a3b8ead5b54e7c85c17a70e5f13b15",
            "value": "â€‡1.84M/?â€‡[00:00&lt;00:00,â€‡37.4MB/s]"
          }
        },
        "0a7d5704d90e4fc8845ef91d7664964c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a8ae4fc29e14f44a63a8b4a6ae3e099": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7744fd498ccc4d7f94c8b5ff737750b2",
              "IPY_MODEL_cbb10b1f649444e1b8d3e99bea419b5f",
              "IPY_MODEL_91fef0873dd84b2eb8eb4e2019a41a44"
            ],
            "layout": "IPY_MODEL_af452aa0f6d44f959b8c5df73bc15a19"
          }
        },
        "0b1de8be994b4f89a8fccfea2647b119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d92c11992df4036b1cf79e9b8f271ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50394728447742f8ab2b9ea0c789b0fe",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_94471f42c68e46a88584fcf9b27e136d",
            "value": "tokenizer_config.json:â€‡"
          }
        },
        "1b8605ad0efc446b933095c51c2edb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8aa4c8cddba42a99ca326db2e0a54ab",
              "IPY_MODEL_c6052d0e1d0b4db69f5794bfb1e8a41c",
              "IPY_MODEL_a642c8b50c244e719df3f924c5b9453b"
            ],
            "layout": "IPY_MODEL_db212ecce5c846fbb02f88af9ae5fef1"
          }
        },
        "1f19bec21c9c4171bb0182a659287b67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25bb4ec9ea69435db6aba5608f364380": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "286f53939041443480b54ed3ce63da4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28942080885443a48e7182812a7ef4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "295013c87f904931b90f8b4a40c60743": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e6b77fef3bf46abb1d203e5b38cb729": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_758343ec90b64d8a9cbc587df2323333",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0b1de8be994b4f89a8fccfea2647b119",
            "value": "added_tokens.json:â€‡100%"
          }
        },
        "30e3e207f63b49c580e6acfd2fe5fd11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31a314f814934e5698428c9b61662d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43e3b728089f43e08738eb543389f668",
            "max": 9435,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_501dca2eaa1b413385d2418364c31f4d",
            "value": 9435
          }
        },
        "39e3dbed96ff42c3a355dc84fb4abffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d415db0ea3840c89569405d0d91f6a1",
            "max": 140,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8579040b5b424f50b172cac93c0337b2",
            "value": 140
          }
        },
        "3d415db0ea3840c89569405d0d91f6a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f5ae2202076400fb54344e18779b3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f6775dcd2d34eebbf3e8d7cd7f3f491": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a04ff0ae6ba4257b1975038a051fd16",
              "IPY_MODEL_31a314f814934e5698428c9b61662d87",
              "IPY_MODEL_c65af38f5d284e0aa51a2cf78c031858"
            ],
            "layout": "IPY_MODEL_5aa7ec39b00f4efda2a0a3dbe6b353d4"
          }
        },
        "41ad9837117e49b8b9b5dc4c1bc313fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42ee35a06dd24877863ef64c5d35a110": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66f7285e691d4468b7afdfdf1ccb5ef7",
            "max": 2264298476,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05ce92be53854e3eac5050c08e639622",
            "value": 2264298476
          }
        },
        "43e3b728089f43e08738eb543389f668": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "467cb87239464e7c86999290f82e87a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "501dca2eaa1b413385d2418364c31f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50394728447742f8ab2b9ea0c789b0fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e81bc3083643eb87994a1037b1fbcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa7ec39b00f4efda2a0a3dbe6b353d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c068acf5c8441da8ad8c62028f0c5a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c5afb1b5d884befbe7787cd3f19d3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f5cfa7f286e4af1905d39af56fa7ec9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b11ee4fa36084283af79f3d3f08e9c29",
            "value": "â€‡2.26G/2.26Gâ€‡[00:04&lt;00:00,â€‡697MB/s]"
          }
        },
        "5e1bd63d76a64b7094cebb715d05f93f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f7285e691d4468b7afdfdf1ccb5ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68134aea4859481cbf54529bff179c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf976bc18e1422d8af57957ef2e7572",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e5640336d2ee4aa0ac9f41a5466b193f",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "6853f2a36b364209ab590c793d870bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ed57d70f85496a8dc9e85928bc5599": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6c0b2b0fcf824382b0356d3785ae1a82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e4e1e71679b41bba4ffcd99f6f15063": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7c4c4cdd6634cfdbdfd77a2dbfe2960",
              "IPY_MODEL_39e3dbed96ff42c3a355dc84fb4abffa",
              "IPY_MODEL_c4b4200125784d979ddf247ea910b7d0"
            ],
            "layout": "IPY_MODEL_71db81ab8c7c42aab9eea2b4136a5125"
          }
        },
        "6f5cfa7f286e4af1905d39af56fa7ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70a3b8ead5b54e7c85c17a70e5f13b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70d77c58f0b64463b772d8c9b7c546b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71db81ab8c7c42aab9eea2b4136a5125": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "723095be893c471b9c46d21418ba046f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86653629c2fd417c80c760fae1d84c6f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_74f02c5c57164323a2921836d26f2acd",
            "value": "â€‡293/293â€‡[00:00&lt;00:00,â€‡40.5kB/s]"
          }
        },
        "728b24fe331a44ce8308ddeac8052e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a09599d90bd24e1dbbd10056f1c892f6",
              "IPY_MODEL_8378dfaebb4f483bb679f70f0a4a5fb0",
              "IPY_MODEL_09f511ebba334065812f785d1c4bcad3"
            ],
            "layout": "IPY_MODEL_78e0ea6bc2ae4947bb0c283b94943299"
          }
        },
        "74f02c5c57164323a2921836d26f2acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "750e206db467469ca3ac21ae921f54f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "758343ec90b64d8a9cbc587df2323333": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7744fd498ccc4d7f94c8b5ff737750b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_295013c87f904931b90f8b4a40c60743",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b71b5d1e9d364337a992fa67b3458869",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "78e0ea6bc2ae4947bb0c283b94943299": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "808b4d509cc44a4495b5d7d43785d38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d92c11992df4036b1cf79e9b8f271ef",
              "IPY_MODEL_819e41877052441ebfae19b50365b02b",
              "IPY_MODEL_f6816d58d4c84130a25529a0ec10a667"
            ],
            "layout": "IPY_MODEL_5e1bd63d76a64b7094cebb715d05f93f"
          }
        },
        "81569628f2094766b4cdd304ac353823": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "819e41877052441ebfae19b50365b02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68ed57d70f85496a8dc9e85928bc5599",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_467cb87239464e7c86999290f82e87a8",
            "value": 1
          }
        },
        "8378dfaebb4f483bb679f70f0a4a5fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_750e206db467469ca3ac21ae921f54f3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_906cad77481843c2bdca9538e5e95db2",
            "value": 1
          }
        },
        "8579040b5b424f50b172cac93c0337b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86653629c2fd417c80c760fae1d84c6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a5aaf2d22734347b8169824e772f034": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bfb0fdd07d048c595500f99a9f011e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e6b77fef3bf46abb1d203e5b38cb729",
              "IPY_MODEL_e4a4f10c04514b448cdfa1e174ccd59c",
              "IPY_MODEL_723095be893c471b9c46d21418ba046f"
            ],
            "layout": "IPY_MODEL_d3d748559ed54931a0717002d2a7cc30"
          }
        },
        "8f7d1cb78dbe4c99bee09167024b326b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "906cad77481843c2bdca9538e5e95db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91fef0873dd84b2eb8eb4e2019a41a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e81bc3083643eb87994a1037b1fbcc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_deec8f2626a64a9bbf854f20e1300f61",
            "value": "â€‡571/571â€‡[00:00&lt;00:00,â€‡64.9kB/s]"
          }
        },
        "94471f42c68e46a88584fcf9b27e136d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a04ff0ae6ba4257b1975038a051fd16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eccede645f12488b89b64a033ff3974b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ebc3bfaa0df54fb4b465a8be5f173c77",
            "value": "Map:â€‡100%"
          }
        },
        "a09599d90bd24e1dbbd10056f1c892f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deaa25c5dc5a419d837c2cad564660f0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0a7d5704d90e4fc8845ef91d7664964c",
            "value": "tokenizer.json:â€‡"
          }
        },
        "a642c8b50c244e719df3f924c5b9453b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0c2288a067b46049523b96215bd0825",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_25bb4ec9ea69435db6aba5608f364380",
            "value": "â€‡500k/500kâ€‡[00:00&lt;00:00,â€‡3.94MB/s]"
          }
        },
        "a7c4c4cdd6634cfdbdfd77a2dbfe2960": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c0b2b0fcf824382b0356d3785ae1a82",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_28942080885443a48e7182812a7ef4e7",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "af452aa0f6d44f959b8c5df73bc15a19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0c2288a067b46049523b96215bd0825": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11ee4fa36084283af79f3d3f08e9c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b15eefacf37344919620503d6aadff53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68134aea4859481cbf54529bff179c3c",
              "IPY_MODEL_42ee35a06dd24877863ef64c5d35a110",
              "IPY_MODEL_5c5afb1b5d884befbe7787cd3f19d3bc"
            ],
            "layout": "IPY_MODEL_f98578029de8456ca7107ada3cb4ddee"
          }
        },
        "b5db3571622645fab9e5c892b9c761c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71b5d1e9d364337a992fa67b3458869": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba9332e81b5949049fb84fb5a44e5fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4b4200125784d979ddf247ea910b7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a5aaf2d22734347b8169824e772f034",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8f7d1cb78dbe4c99bee09167024b326b",
            "value": "â€‡140/140â€‡[00:00&lt;00:00,â€‡18.6kB/s]"
          }
        },
        "c6052d0e1d0b4db69f5794bfb1e8a41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5db3571622645fab9e5c892b9c761c9",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e479f53267a54a2da3d2a7cdcf00fe56",
            "value": 499723
          }
        },
        "c65af38f5d284e0aa51a2cf78c031858": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f19bec21c9c4171bb0182a659287b67",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_81569628f2094766b4cdd304ac353823",
            "value": "â€‡9435/9435â€‡[01:09&lt;00:00,â€‡135.93â€‡examples/s]"
          }
        },
        "c8aa4c8cddba42a99ca326db2e0a54ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_286f53939041443480b54ed3ce63da4a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_70d77c58f0b64463b772d8c9b7c546b2",
            "value": "tokenizer.model:â€‡100%"
          }
        },
        "cbb10b1f649444e1b8d3e99bea419b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30e3e207f63b49c580e6acfd2fe5fd11",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba9332e81b5949049fb84fb5a44e5fd1",
            "value": 571
          }
        },
        "ccf976bc18e1422d8af57957ef2e7572": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3d748559ed54931a0717002d2a7cc30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae066380e9a48f69bdbd7473c860569": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db212ecce5c846fbb02f88af9ae5fef1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deaa25c5dc5a419d837c2cad564660f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deec8f2626a64a9bbf854f20e1300f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e479f53267a54a2da3d2a7cdcf00fe56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4a4f10c04514b448cdfa1e174ccd59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6853f2a36b364209ab590c793d870bc3",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f5ae2202076400fb54344e18779b3d9",
            "value": 293
          }
        },
        "e5640336d2ee4aa0ac9f41a5466b193f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebc3bfaa0df54fb4b465a8be5f173c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eccede645f12488b89b64a033ff3974b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6816d58d4c84130a25529a0ec10a667": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41ad9837117e49b8b9b5dc4c1bc313fa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dae066380e9a48f69bdbd7473c860569",
            "value": "â€‡3.37k/?â€‡[00:00&lt;00:00,â€‡420kB/s]"
          }
        },
        "f98578029de8456ca7107ada3cb4ddee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
